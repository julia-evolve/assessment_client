import streamlit as st
import pandas as pd
import tempfile
import requests
import re
from pathlib import Path

st.set_page_config(
    page_title="Assessment Client",
    layout="wide"
)

REQUIRED_COMPETENCY_COLUMNS = ["name", "description", "level_0", "level_1", "level_2", "level_3"]
REQUIRED_QA_COLUMNS = ["Email", "–í–æ–ø—Ä–æ—Å", "–û—Ç–≤–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞", "–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏"]


def normalize_spaces(text: str) -> str:
    if text is None:
        return ''
    return re.sub(r'\s+', ' ', str(text)).strip()


def drop_rows_with_nan(df: pd.DataFrame, required_cols, dataset_name: str) -> pd.DataFrame:
    missing_columns = [col for col in required_cols if col not in df.columns]
    if missing_columns:
        raise ValueError(f"{dataset_name}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing_columns)}")

    rows_to_drop = []
    for idx, row in df.iterrows():
        nan_columns = [col for col in required_cols if pd.isna(row[col])]
        if nan_columns:
            rows_to_drop.append((idx, nan_columns))

    if not rows_to_drop:
        return df

    for idx, nan_columns in rows_to_drop:
        excel_row_number = idx + 2  # +2 to account for header row in Excel export
        st.warning(
            f"{dataset_name}: —Å—Ç—Ä–æ–∫–∞ {excel_row_number} —É–¥–∞–ª–µ–Ω–∞ –∏–∑-–∑–∞ NaN –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö: "
            + ", ".join(nan_columns)
        )

    cleaned_df = df.drop(index=[idx for idx, _ in rows_to_drop]).reset_index(drop=True)
    return cleaned_df


def validate_competency_data(df_competency: pd.DataFrame, df_qa: pd.DataFrame):
    errors = []

    if 'name' not in df_competency.columns:
        errors.append("–í –º–∞—Ç—Ä–∏—Ü–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'name'.")
        matrix_names = pd.Series(dtype=str)
    else:
        matrix_names = df_competency['name'].fillna('').astype(str).map(normalize_spaces)

        comma_mask = matrix_names.str.contains(',', regex=False)
        if comma_mask.any():
            offending = matrix_names[comma_mask].unique().tolist()
            errors.append(
                "–í –º–∞—Ç—Ä–∏—Ü–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –∑–∞–ø—Ä–µ—â–µ–Ω—ã –∑–∞–ø—è—Ç—ã–µ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏. –ò—Å–ø—Ä–∞–≤—å—Ç–µ: "
                + ", ".join(offending[:5])
                + (" ..." if len(offending) > 5 else "")
            )

        parentheses_mask = matrix_names.str.contains(r'[()]', regex=True)
        if parentheses_mask.any():
            offending = matrix_names[parentheses_mask].unique().tolist()
            errors.append(
                "–í –º–∞—Ç—Ä–∏—Ü–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π —É–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö –∏–∑ 'name'. –ù–∞–π–¥–µ–Ω—ã: "
                + ", ".join(offending[:5])
                + (" ..." if len(offending) > 5 else "")
            )

        empty_mask = matrix_names.eq('')
        if empty_mask.any():
            errors.append("–í –º–∞—Ç—Ä–∏—Ü–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –Ω–∞–π–¥–µ–Ω—ã –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–µ 'name'.")

    if '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏' not in df_qa.columns:
        errors.append("–í —Ç–∞–±–ª–∏—Ü–µ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏'.")
        qa_competencies_series = pd.Series(dtype=str)
    else:
        qa_competencies_series = df_qa['–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏'].fillna('').astype(str).map(normalize_spaces)

        qa_parentheses_mask = qa_competencies_series.str.contains(r'[()]', regex=True)
        if qa_parentheses_mask.any():
            offending_rows = df_qa.loc[qa_parentheses_mask, ['Email', '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏']]
            details = "; ".join(
                f"Email {row.get('Email', 'N/A')}: {row['–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏']}" for _, row in offending_rows.head(5).iterrows()
            )
            if len(offending_rows) > 5:
                details += " ..."
            errors.append(
                "–£–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö –≤ –∫–æ–ª–æ–Ω–∫–µ '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏' —Ç–∞–±–ª–∏—Ü—ã –æ—Ç–≤–µ—Ç–æ–≤. –ü—Ä–∏–º–µ—Ä—ã: " + details
            )

    qa_competency_names = set()
    for value in qa_competencies_series:
        if not value:
            continue
        parts = [part.strip() for part in value.split(',') if part.strip()]
        qa_competency_names.update(parts)

    matrix_name_set = set(matrix_names[matrix_names != ''])

    missing_in_matrix = sorted(qa_competency_names - matrix_name_set)
    missing_in_qa = sorted(matrix_name_set - qa_competency_names)

    if missing_in_matrix:
        errors.append(
            "–í —Ç–∞–±–ª–∏—Ü–µ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –≤ –º–∞—Ç—Ä–∏—Ü–µ: "
            + ", ".join(missing_in_matrix)
        )
    if missing_in_qa:
        errors.append(
            "–í –º–∞—Ç—Ä–∏—Ü–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ –æ—Ç–≤–µ—Ç–æ–≤: "
            + ", ".join(missing_in_qa)
        )

    if errors:
        raise ValueError("\n".join(errors))




def process_excel_files(file1, file2):
    """
    Process two Excel files and create JSON payloads for each email.
    
    Args:
        file1: First Excel file (competency matrix)
        file2: Second Excel file (questions and answers)
    
    Returns:
        List of tuples containing (email, json_payload)
    """
    # Save uploaded files to temporary directory
    with tempfile.TemporaryDirectory() as temp_dir:
        # Save first file (competency matrix)
        file1_path = Path(temp_dir) / file1.name
        with open(file1_path, 'wb') as f:
            f.write(file1.getbuffer())
        
        # Save second file (questions and answers)
        file2_path = Path(temp_dir) / file2.name
        with open(file2_path, 'wb') as f:
            f.write(file2.getbuffer())
        
        # Read Excel files
        df_competency = pd.read_excel(file1_path)
        df_qa = pd.read_excel(file2_path)

        # Drop rows with NaN in required columns and inform the user
        df_competency = drop_rows_with_nan(df_competency, REQUIRED_COMPETENCY_COLUMNS, "–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")
        df_qa = drop_rows_with_nan(df_qa, REQUIRED_QA_COLUMNS, "–¢–∞–±–ª–∏—Ü–∞ –æ—Ç–≤–µ—Ç–æ–≤")

        validate_competency_data(df_competency, df_qa)

        # Group data by email
        results = []
        competency_matrix = []

        level_columns = [col for col in df_competency.columns if col.startswith('level_')]

        for _, row in df_competency.iterrows():
            normalized_name = normalize_spaces(row['name']) if 'name' in row else ''
            # Create competency with levels
            competency = {
                "name": normalized_name,
                "description": str(row.get('description', '')).strip() if pd.notna(row.get('description')) else None,
                "levels": []
            }

            for level_col in level_columns:
                if level_col in row and pd.notna(row[level_col]) and str(row[level_col]).strip():
                    competency["levels"].append({
                        "name": level_col,
                        "description": str(row[level_col]).strip()
                    })

            competency_matrix.append(competency)

        if 'Email' in df_qa.columns:
            emails = df_qa['Email'].unique()
            
            for email in emails:
                one_student = df_qa[df_qa['Email'] == email]
  
                # Build JSON structure
                json_payload = {
                    "competency_matrix": competency_matrix,
                    "questions_and_answers": [],
                    "webhook_url": "https://ntfy.sh/assessment",
                    "user_email": email,
                    "user_name": email
                }
                
                for _, row in one_student.iterrows():
                    qa_entry = {}
                    if '–í–æ–ø—Ä–æ—Å' in row:
                        qa_entry['question'] = str(row['–í–æ–ø—Ä–æ—Å'])
                    if '–û—Ç–≤–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞' in row:
                        qa_entry['answer'] = str(row['–û—Ç–≤–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞'])
                    if '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏' in row:
                        competencies_value = normalize_spaces(row['–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏'])
                        qa_entry['competencies'] = [part.strip() for part in competencies_value.split(',') if part.strip()]
                    
                    if qa_entry:
                        json_payload["questions_and_answers"].append(qa_entry)
                
                
        results.append((email, json_payload))
        
        return results


def send_to_assessment_api(email, payload, api_url):
    """
    Send JSON payload to the assessment API.
    
    Args:
        email: Email address
        payload: JSON payload to send
        api_url: API endpoint URL
    
    Returns:
        Response object or error message
    """
    try:
        headers = {'Content-Type': 'application/json'}
        response = requests.post(api_url, json=payload, headers=headers, timeout=30)
        return response
    except Exception as e:
        return str(e)


def main():
    st.title("Assessment Client")
    st.write("–ó–≤–≥—Ä—É–∑–∏—Ç–µ –¥–≤–∞ Excel —Ñ–∞–π–ª–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ API –æ—Ü–µ–Ω–∫–∏.")
    
    # Configuration section
    st.sidebar.header("Configuration")
    api_url = st.sidebar.selectbox(
        "Assessment API URL",
        options=[
            "https://evolveaiserver-production.up.railway.app/evaluate_open_assessments",
            "http://localhost:8000/evaluate_open_assessments",
            "Custom"
        ],
        index=0,
        help="Select the API endpoint URL"
    )
    if api_url == "Custom":
        api_url = st.sidebar.text_input(
            "Custom API URL",
            value="https://evolveaiserver-production.up.railway.app/evaluate_open_assessments",
            help="Enter the API endpoint URL"
        )
        
    # File upload section
    st.header("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")
        st.write("–û–∂–∏–¥–∞–µ–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã:")
        st.write("[name, description, level_0, level_1, level_2, level_3]")
        st.caption("üö´ –í –∫–æ–ª–æ–Ω–∫–µ name –Ω–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–ø—è—Ç—ã–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö.")
        
        # Download example button
        example_file_path = Path("examples/matrix_example.xlsx")
        if not example_file_path.exists():
            example_file_path = Path("/app/examples/matrix_example.xlsx")
        if example_file_path.exists():
            with open(example_file_path, "rb") as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä",
                    data=f,
                    file_name="matrix_example.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        
        file1 = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª –º–∞—Ç—Ä–∏—Ü—ã –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π",
            type=['xlsx', 'xls'],
            key="file1"
        )
    
    with col2:
        st.subheader("–í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã")
        st.write("–û–∂–∏–¥–∞–µ–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã:")
        st.write("[Email, –í–æ–ø—Ä–æ—Å, –û—Ç–≤–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞, –ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏]")
        st.caption("üö´ –í –∫–æ–ª–æ–Ω–∫–µ '–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏' –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö.")
        
        # Download example button
        example_file_path = Path("examples/qa_example.xlsx")
        if not example_file_path.exists():
            example_file_path = Path("/app/examples/qa_example.xlsx")
        if example_file_path.exists():
            with open(example_file_path, "rb") as f:
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä",
                    data=f,
                    file_name="qa_example.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        
        file2 = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ Excel —Ñ–∞–π–ª —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏",
            type=['xlsx', 'xls'],
            key="file2"
        )
    
    # Upload button
    if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å", type="primary"):
        if file1 is None or file2 is None:
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±–∞ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π.")
        else:
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤..."):
                try:
                    # Process the Excel files
                    results = process_excel_files(file1, file2)
                    
                    if not results:
                        st.warning("No data found to process. Please check that your Excel files have an 'email' column.")
                    else:
                        st.success(f"Found {len(results)} email(s) to process")
                        
                        # Send each payload to the API
                        progress_bar = st.progress(0)
                        status_container = st.container()
                        
                        for idx, (email, payload) in enumerate(results):
                            with status_container:
                                st.write(f"Processing email: {email}")
                                
                                # Show JSON payload in expander
                                with st.expander(f"View JSON for {email}"):
                                    st.json(payload)
                                
                                # Send to API
                                response = send_to_assessment_api(email, payload, api_url)
                                
                                if isinstance(response, str):
                                    # Error occurred
                                    st.error(f"Error for {email}: {response}")
                                else:
                                    # Check response status
                                    if response.status_code == 200:
                                        st.success(f"‚úÖ Successfully sent data for {email}")
                                    else:
                                        st.warning(f"‚ö†Ô∏è API returned status {response.status_code} for {email}: {response.text}")
                            
                            # Update progress
                            progress_bar.progress((idx + 1) / len(results))
                        
                        st.balloons()
                        st.success("All emails processed!")
                
                except Exception as e:
                    st.error(f"Error processing files: {str(e)}")
                    st.exception(e)
    
    # Information section
    st.divider()
    st.header("How to Use")
    st.markdown("""
### 1. **–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ Excel —Ñ–∞–π–ª—ã:**.  
    - –§–∞–π–ª 1 (–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π): –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã `name`, `description`, `level_0`, `level_1`, `level_2`, `level_3`
    - –í –∫–æ–ª–æ–Ω–∫–µ `name` **–Ω–µ–ª—å–∑—è** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–ø—è—Ç—ã–µ, –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–µ–∫—Å—Ç –≤ –∫—Ä—É–≥–ª—ã—Ö —Å–∫–æ–±–∫–∞—Ö
    - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è
    - –í—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –ø–µ—Ä–≤–æ–º –ª–∏—Å—Ç–µ Excel —Å –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏
---
    - –§–∞–π–ª 2 (–í–æ–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã): –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–æ–ª–±—Ü—ã `Email`, `–í–æ–ø—Ä–æ—Å`, `–û—Ç–≤–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–∞`, `–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏`
    - –í –∫–æ–ª–æ–Ω–∫–µ `–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏` –∑–∞–ø—Ä–µ—â—ë–Ω —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö, –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ—á–∏—Å–ª—è—é—Ç—Å—è —á–µ—Ä–µ–∑ `", "`
    - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –ø–µ—Ä–≤–æ–º –ª–∏—Å—Ç–µ Excel
    - –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ —Å—Ç—Ä–æ–≥–æ, –±–µ–∑ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö —è—á–µ–µ–∫

### 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:
       - [https://ntfy.sh/assessment](https://ntfy.sh/assessment)
    """)


if __name__ == "__main__":
    main()
